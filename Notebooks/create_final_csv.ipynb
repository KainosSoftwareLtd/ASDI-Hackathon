{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import dask\n",
    "from pandarallel import pandarallel\n",
    "\n",
    " #multiprocess works better within Jupyter Notebooks than multiprocessing package\n",
    "from multiprocess import Pool\n",
    "from multiprocess import cpu_count\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "ROOT = pathlib.Path().absolute().parent.as_posix()\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)\n",
    "    \n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# npartitions : Integer. The number of partitions to distribute the data into for dask processing. Default: 2*cpu_count()\n",
    "\n",
    "# dask_threshold : Float. The amount of seconds to use for estimating whether to use dask or pandas apply. Default: 1 second\n",
    "\n",
    "# scheduler : String. Whether to use threads or processes for the dask scheduler Default: processes\n",
    "\n",
    "# progress_bar : Boolean. Whether to turn the progress bar on or off. Default: True\n",
    "\n",
    "# progress_bar_desc : String. Progress Bar Description Default: None\n",
    "\n",
    "# allow_dask_on_strings : Boolean. Allows user to enable dask parallel processing on string data Default: False\n",
    "\n",
    "# force_parallel : Boolean. Allows user to override swifter algorithm and jump straight to using dask processing Default: False\n",
    "\n",
    "\n",
    "from swifter import set_defaults\n",
    "set_defaults(\n",
    "    npartitions=None,\n",
    "    dask_threshold=1,\n",
    "    scheduler=\"processes\",\n",
    "    progress_bar=True,\n",
    "    progress_bar_desc=None,\n",
    "    allow_dask_on_strings=False,\n",
    "    force_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df_filled = pd.read_csv(ROOT + '/Spikes/Dash/data/points_df.csv', index_col = 0)\n",
    "\n",
    "def parallelize(data, func, num_of_processes=cpu_count()):\n",
    "    data_split = np.array_split(data, num_of_processes)\n",
    "    pool = Pool(num_of_processes)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def run_on_subset(func, data_subset):\n",
    "    return data_subset.apply(func, axis=1)\n",
    "\n",
    "#replace df.apply(some_func, axis=1) with parallelize_on_rows(df, some_func) \n",
    "def parallelize_on_rows(data, func, num_of_processes=8):\n",
    "    return parallelize(data, partial(run_on_subset, func), num_of_processes)\n",
    "\n",
    "\n",
    "def apply_aq_functions(points_df_filled):\n",
    "    #molar mass constants\n",
    "    co_molar_mass = 28.01\n",
    "    no2_molar_mass = 46.0055\n",
    "    o3_molar_mass = 48\n",
    "    so2_molar_mass = 64.066\n",
    "\n",
    "    #apply aq functions to each row (using latitude and longitude columns) and multiply by associated molar mass to give g/m2\n",
    "    #axis = 1, apply function to each row\n",
    "    \n",
    "    points_df_filled['Value_co'] = points_df_filled.apply(lambda row : co_function(row['Latitude'], row['Longitude']) * co_molar_mass, axis=1)\n",
    "    print('co_function complete')\n",
    "    points_df_filled['Value_no2'] = points_df_filled.apply(lambda row : no2_function(row['Latitude'], row['Longitude']) * no2_molar_mass, axis=1)\n",
    "    print('no2_function complete')\n",
    "    points_df_filled['Value_o3'] = points_df_filled.apply(lambda row : o3_function(row['Latitude'], row['Longitude']) * o3_molar_mass, axis=1)\n",
    "    print('o3_function complete')\n",
    "    points_df_filled['Value_so2'] = points_df_filled.apply(lambda row : so2_function(row['Latitude'], row['Longitude']) * so2_molar_mass, axis=1)\n",
    "    print('so2_function complete')\n",
    "    points_df_filled['Value_ai'] = points_df_filled.apply(lambda row : ai_function(row['Latitude'], row['Longitude']), axis=1)\n",
    "    print('ai_function complete')\n",
    "    \n",
    "    # points_df_filled['Value_co'] = points_df_filled.swifter.apply(lambda row : co_function(row['Latitude'], row['Longitude']) * co_molar_mass, axis=1)\n",
    "    # print('co_function complete')\n",
    "    # points_df_filled['Value_no2'] = points_df_filled.swifter.apply(lambda row : no2_function(row['Latitude'], row['Longitude']) * no2_molar_mass, axis=1)\n",
    "    # print('no2_function complete')\n",
    "    # points_df_filled['Value_o3'] = points_df_filled.swifter.apply(lambda row : o3_function(row['Latitude'], row['Longitude']) * o3_molar_mass, axis=1)\n",
    "    # print('o3_function complete')\n",
    "    # points_df_filled['Value_so2'] = points_df_filled.swifter.apply(lambda row : so2_function(row['Latitude'], row['Longitude']) * so2_molar_mass, axis=1)\n",
    "    # print('so2_function complete')\n",
    "    # points_df_filled['Value_ai'] = points_df_filled.swifter.apply(lambda row : ai_function(row['Latitude'], row['Longitude']), axis=1)\n",
    "    # print('ai_function complete')\n",
    "    \n",
    "    #Pandarallel does what Multiprocess does just under the hood but adds progress bar\n",
    "    # pandarallel.initialize(progress_bar=True)\n",
    "    \n",
    "    # points_df_filled['Value_co'] = points_df_filled.parallel_apply(lambda row : co_function(row['Latitude'], row['Longitude']) * co_molar_mass, axis=1)\n",
    "    # print('co_function complete')\n",
    "    # points_df_filled['Value_no2'] = points_df_filled.parallel_apply(lambda row : no2_function(row['Latitude'], row['Longitude']) * no2_molar_mass, axis=1)\n",
    "    # print('no2_function complete')\n",
    "    # points_df_filled['Value_o3'] = points_df_filled.parallel_apply(lambda row : o3_function(row['Latitude'], row['Longitude']) * o3_molar_mass, axis=1)\n",
    "    # print('o3_function complete')\n",
    "    # points_df_filled['Value_so2'] = points_df_filled.parallel_apply(lambda row : so2_function(row['Latitude'], row['Longitude']) * so2_molar_mass, axis=1)\n",
    "    # print('so2_function complete')\n",
    "    # points_df_filled['Value_ai'] = points_df_filled.parallel_apply(lambda row : ai_function(row['Latitude'], row['Longitude']), axis=1)\n",
    "    # print('ai_function complete')\n",
    "    \n",
    "    return points_df_filled\n",
    "\n",
    "def normalise(points_df_filled):\n",
    "    norm_cols = ['Value_co', 'Value_no2', 'Value_o3', 'Value_so2', 'Value_ai']\n",
    "    #normalise each aq metric value set between 1 and 0 where 0 = 0% and 1 = 20%\n",
    "    for i in points_df_filled[norm_cols]:   #normalise aq value columns\n",
    "        points_df_filled['norm_' + i]=(points_df_filled[i]-points_df_filled[i].min())/(points_df_filled[i].max()-points_df_filled[i].min())\n",
    "    \n",
    "    return points_df_filled\n",
    "\n",
    "def aqs_function(aq1, aq2, aq3, aq4, aq5):\n",
    "    #smaller value = better air quality\n",
    "    aqs = (aq1 * (20/100)) + (aq2 * (20/100)) + (aq3 * (20/100)) + (aq4 * (20/100)) + (aq5 * (20/100))\n",
    "    return aqs\n",
    "\n",
    "def apply_aqs_function(points_df_filled):\n",
    "    #assumption: each metric is worth 20% of AQS, 100 / 5 metrics\n",
    "    #apply calculate_aqi function to each row of the 5 aq columns\n",
    "    points_df_filled['AQ_score'] = points_df_filled.swifter.apply(lambda row : aqs_function(row['norm_Value_co'], \n",
    "                                                                                            row['norm_Value_no2'], \n",
    "                                                                                            row['norm_Value_o3'], \n",
    "                                                                                            row['norm_Value_so2'], \n",
    "                                                                                            row['norm_Value_ai']), axis=1)\n",
    "    \n",
    "    #drop normalised columns (as unuseful now)\n",
    "    points_df_filled = points_df_filled.drop(['norm_Value_co', 'norm_Value_no2', 'norm_Value_o3', 'norm_Value_so2', 'norm_Value_ai'], axis = 1)\n",
    "    \n",
    "    return points_df_filled\n",
    "\n",
    "def apply_popd_function(points_df_filled):\n",
    "    #same as above apply aq functions but with...\n",
    "    #popdensity_function\n",
    "    points_df_filled['Pop_density'] = points_df_filled.swifter.apply(lambda row : popdensity_function(row['Latitude'], row['Longitude']), axis=1)\n",
    "    \n",
    "    return points_df_filled\n",
    "\n",
    "def greenspace_score_function(points_df_filled, aqs, pop_density, land_type):\n",
    "    #Air Quality Score\n",
    "    aqs_pct = 100 - sum(popd_pct)\n",
    "    aqs_weight = 1\n",
    "    \n",
    "    #Population Density\n",
    "    popd_pct = 50/100\n",
    "    #50m2 per capita according to WHO standards or 100m2 (our resolution) per 2 people\n",
    "    standard_gs_per_pop_m2 = 50\n",
    "    sum_popd = points_df_filled['Pop_density'].sum()\n",
    "    sum_greenspace_m2 = points_df_filled[points_df_filled['Land_type'] == 'greenspace'].sum() * 100   #multiplied by resolution\n",
    "    gs_per_capita = sum_greenspace_m2 / sum_popd\n",
    "    diff_standard_real = standard_gs_per_pop_m2 - gs_per_capita\n",
    "    #if current greenspace per capita is BETTER than WHO standards, it is LESS likely greenspace is required so PENALISE lower weighting\n",
    "    if diff_standard_real < 0:   #check if negative\n",
    "        popd_weight = abs(diff_standard_real) / standard_gs_per_pop_m2   #will reduce weight below 1, decreasing contribution of pop density to greenspace score\n",
    "    #if current greenspace per capita is WORSE than WHO standards, it is MORElikely greenspace is required so REWARD higher weighting\n",
    "    elif diff_standard_real > 0:\n",
    "        popd_weight = abs(diff_standard_real) / standard_gs_per_pop_m2   #will increase weight above 1, increasing contribution of pop density to greenspace score\n",
    "    else:\n",
    "        popd_weight = 1   #no difference means weighting is cancelled out\n",
    "    \n",
    "    #Land Type\n",
    "    if (land_type == 'hospital'):\n",
    "        penalty = 0\n",
    "    elif (land_type == 'hospital'):\n",
    "        penalty = 0\n",
    "    elif land_type in ['hospital', 'hospital']:\n",
    "        penalty = 0\n",
    "        \n",
    "    Greenspace_score = ((aqs_weight * aqs) * aqs_pct) + ((popd_weight * pop_density) * popd_pct) * penalty\n",
    "    return Greenspace_score\n",
    "    \n",
    "def apply_greenspace_score_function(points_df_filled):\n",
    "    points_df_filled['Greenspace_score'] = points_df_filled.swifter.apply(lambda row : greenspace_score_function(row['Land_type'], \n",
    "                                                                                            row['AQ_score'], \n",
    "                                                                                            row['Pop_density']), axis=1)\n",
    "\n",
    "def fill_df(points_df_filled):\n",
    "    points_df_filled = apply_aq_functions(points_df_filled)\n",
    "    print('apply_aq_functions complete')\n",
    "    points_df_filled = normalise(points_df_filled)\n",
    "    print('normalisation of aq values complete')\n",
    "    points_df_filled = apply_aqs_function(points_df_filled)\n",
    "    print('apply_aqs_function complete')\n",
    "    \n",
    "    # n_cores = cpu_count()\n",
    "    # df_splits = np.array_split(points_df_filled, n_cores)\n",
    "    # pool = Pool(n_cores)\n",
    "    # results = pool.map(apply_popd_function, df_splits)\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "    # points_df_filled = pd.concat(results)\n",
    "    # print('apply_popd_function complete')\n",
    "    \n",
    "    # try:\n",
    "    #     points_df_filled = apply_greenspace_score_function(points_df_filled)\n",
    "    #     print('apply_greenspace_score_function complete')\n",
    "    # except:\n",
    "    #     pass   #remove when complete\n",
    "    \n",
    "    return points_df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [05:50<00:00, 21.93s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co_function complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [24:35<00:00, 92.24s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no2_function complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [02:00<00:00,  7.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o3_function complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [01:52<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so2_function complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [02:11<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_function complete\n",
      "apply_aq_functions complete\n",
      "normalisation of aq values complete\n",
      "apply_aqs_function complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=0'>1</a>\u001b[0m points_df_filled \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(ROOT \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Spikes/Dash/data/points_df.csv\u001b[39m\u001b[39m'\u001b[39m, index_col \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=2'>3</a>\u001b[0m fill_df(points_df_filled)\n",
      "\u001b[1;32m/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb Cell 4\u001b[0m in \u001b[0;36mfill_df\u001b[0;34m(points_df_filled)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=147'>148</a>\u001b[0m df_splits \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray_split(points_df_filled, n_cores)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=148'>149</a>\u001b[0m pool \u001b[39m=\u001b[39m Pool(n_cores)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=149'>150</a>\u001b[0m results \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(apply_popd_function, df_splits)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=150'>151</a>\u001b[0m pool\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/joshua.grefte/Projects/ASDI/Local_Repo/ASDI-Hackathon/Notebooks/create_final_csv.ipynb#ch0000003?line=151'>152</a>\u001b[0m pool\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/multiprocess/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/multiprocess/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/multiprocess/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points_df_filled = pd.read_csv(ROOT + '/Spikes/Dash/data/points_df.csv', index_col = 0)\n",
    "\n",
    "fill_df(points_df_filled)\n",
    "\n",
    "#save dataframe\n",
    "points_df_filled.to_csv(ROOT + '/Spikes/Dash/data/final_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Value_co</th>\n",
       "      <th>Value_no2</th>\n",
       "      <th>Value_o3</th>\n",
       "      <th>Value_so2</th>\n",
       "      <th>Value_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.737184</td>\n",
       "      <td>-0.620643</td>\n",
       "      <td>0.764264</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>7.248996</td>\n",
       "      <td>0.032141</td>\n",
       "      <td>-1.031149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.737184</td>\n",
       "      <td>-0.617012</td>\n",
       "      <td>0.764304</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>7.250456</td>\n",
       "      <td>0.032148</td>\n",
       "      <td>-1.035486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.737184</td>\n",
       "      <td>-0.613382</td>\n",
       "      <td>0.764350</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>7.250998</td>\n",
       "      <td>0.032186</td>\n",
       "      <td>-1.037714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.737183</td>\n",
       "      <td>-0.609751</td>\n",
       "      <td>0.764624</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>7.251659</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>-1.035978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.737183</td>\n",
       "      <td>-0.606120</td>\n",
       "      <td>0.764288</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>7.252279</td>\n",
       "      <td>0.031958</td>\n",
       "      <td>-1.039697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58243</th>\n",
       "      <td>51.238843</td>\n",
       "      <td>0.312049</td>\n",
       "      <td>0.764161</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>7.310894</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>-0.748909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58244</th>\n",
       "      <td>51.238815</td>\n",
       "      <td>0.315640</td>\n",
       "      <td>0.764524</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>7.310550</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>-0.745427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58245</th>\n",
       "      <td>51.238786</td>\n",
       "      <td>0.319231</td>\n",
       "      <td>0.764969</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>7.310113</td>\n",
       "      <td>0.029139</td>\n",
       "      <td>-0.744029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58246</th>\n",
       "      <td>51.238757</td>\n",
       "      <td>0.322822</td>\n",
       "      <td>0.765131</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>7.311109</td>\n",
       "      <td>0.029128</td>\n",
       "      <td>-0.740657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58247</th>\n",
       "      <td>51.238728</td>\n",
       "      <td>0.326412</td>\n",
       "      <td>0.765508</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>7.309666</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>-0.735046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58248 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Latitude  Longitude  Value_co  Value_no2  Value_o3  Value_so2  \\\n",
       "0      51.737184  -0.620643  0.764264   0.004088  7.248996   0.032141   \n",
       "1      51.737184  -0.617012  0.764304   0.004140  7.250456   0.032148   \n",
       "2      51.737184  -0.613382  0.764350   0.004143  7.250998   0.032186   \n",
       "3      51.737183  -0.609751  0.764624   0.004142  7.251659   0.032087   \n",
       "4      51.737183  -0.606120  0.764288   0.004142  7.252279   0.031958   \n",
       "...          ...        ...       ...        ...       ...        ...   \n",
       "58243  51.238843   0.312049  0.764161   0.002717  7.310894   0.028964   \n",
       "58244  51.238815   0.315640  0.764524   0.002728  7.310550   0.029058   \n",
       "58245  51.238786   0.319231  0.764969   0.002732  7.310113   0.029139   \n",
       "58246  51.238757   0.322822  0.765131   0.002735  7.311109   0.029128   \n",
       "58247  51.238728   0.326412  0.765508   0.002755  7.309666   0.029168   \n",
       "\n",
       "       Value_ai  \n",
       "0     -1.031149  \n",
       "1     -1.035486  \n",
       "2     -1.037714  \n",
       "3     -1.035978  \n",
       "4     -1.039697  \n",
       "...         ...  \n",
       "58243 -0.748909  \n",
       "58244 -0.745427  \n",
       "58245 -0.744029  \n",
       "58246 -0.740657  \n",
       "58247 -0.735046  \n",
       "\n",
       "[58248 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
